{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewly/opt/anaconda3/envs/frac-attn/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewly/opt/anaconda3/envs/frac-attn/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/andrewly/opt/anaconda3/envs/frac-attn/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer_src = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-de-en')  # German tokenizer\n",
    "tokenizer_trg = AutoTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-de')  # English tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, tokenizer_src, src_language, trg_language, max_length):\n",
    "    inputs = [example[src_language] for example in examples[\"translation\"]]\n",
    "    targets = [example[trg_language] for example in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer_src(inputs, text_target=targets, max_length=max_length, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer_trg(targets, max_length=max_length, truncation=True, padding=\"max_length\")[\"input_ids\"]\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "def prepare_data(tokenizer_src, tokenizer_trg, batch_size=4, num_workers=2, test_fraction=0.2, max_length=512):\n",
    "    # Load dataset; ignore validation set (tst2013) and use test set only (tst2014)\n",
    "    src_language, trg_language = 'de', 'en'\n",
    "    dataset = load_dataset(\"ted_talks_iwslt\", language_pair=(src_language, trg_language), year=\"2014\")\n",
    "    dataset = dataset.train_test_split(test_size=test_fraction, shuffle=True)\n",
    "    trainset, testset = dataset['train'], dataset['test']\n",
    "    # Preprocess datasets\n",
    "    tokenized_trainset = trainset.map(lambda examples: preprocess_function(examples, tokenizer_src, src_language, tokenizer_trg, trg_language, max_length), batched=True)\n",
    "    tokenized_testset = testset.map(lambda examples: preprocess_function(examples, tokenizer_src, src_language, tokenizer_trg, trg_language, max_length), batched=True)\n",
    "    # Create dataloaders\n",
    "    trainloader = torch.utils.data.DataLoader(tokenized_trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    testloader = torch.utils.data.DataLoader(tokenized_testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewly/opt/anaconda3/envs/frac-attn/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for ted_talks_iwslt contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/ted_talks_iwslt\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading data: 100%|██████████| 1.67G/1.67G [04:25<00:00, 6.27MB/s] \n",
      "Generating train split: 2972 examples [00:06, 461.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"ted_talks_iwslt\", language_pair=(\"de\", \"en\"), year=\"2014\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 298/298 [00:00<00:00, 2442.14 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_testset = testset.map(lambda examples: preprocess_function(examples, tokenizer_src, \"de\", \"en\", 128), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(tokenized_testset, batch_size=2, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x184fbe3d0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "ix = torch.randint(len(testloader), (batch_size,))\n",
    "x = torch.stack([data.dataset[i][0] for i in ix])\n",
    "y = torch.tensor([data.dataset[i][1] for i in ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"beta\": 1,\n",
    "    \"bandwidth\": 1,\n",
    "    \"sphere_radius\": 1,\n",
    "    \"hidden_size\": 1,\n",
    "    \"num_encoder_layers\": 1,\n",
    "    \"num_decoder_layers\": 1,\n",
    "    \"num_attention_heads\": 1,\n",
    "    \"intermediate_size\": 4, # 4 * hidden_size\n",
    "    \"hidden_dropout_prob\": 0,\n",
    "    \"encoder_dropout_prob\": 0,\n",
    "    \"decoder_dropout_prob\": 0,\n",
    "    \"attention_probs_dropout_prob\": 0,\n",
    "    \"initializer_range\": 0.1,\n",
    "    \"qkv_bias\": True,\n",
    "    \"use_faster_attention\": True,\n",
    "    \"src_vocab_size\": tokenizer_src.vocab_size,\n",
    "    \"src_pad_token_id\": tokenizer_src.pad_token_id,\n",
    "    \"trg_vocab_size\": tokenizer_trg.vocab_size,\n",
    "    \"trg_pad_token_id\": tokenizer_trg.pad_token_id,\n",
    "    \"max_length\": 128,\n",
    "}\n",
    "model = FNSForTranslation(config)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FNSForTranslation(\n",
       "  (encoder): FNSEncoder(\n",
       "    (token_embedding): Embedding(58101, 1, padding_idx=58100)\n",
       "    (positional_embedding): Embedding(128, 1)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): FNSEncoderBlock(\n",
       "        (attention): FasterFNSMultiHeadAttention(\n",
       "          (qkv_projection): Linear(in_features=1, out_features=3, bias=True)\n",
       "          (attn_dropout): Dropout(p=0, inplace=False)\n",
       "          (output_projection): Linear(in_features=1, out_features=1, bias=True)\n",
       "          (output_dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (layernorm_1): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (dense_1): Linear(in_features=1, out_features=4, bias=True)\n",
       "          (activation): NewGELUActivation()\n",
       "          (dense_2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (layernorm_2): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): FNSDecoder(\n",
       "    (token_embedding): Embedding(58101, 1, padding_idx=58100)\n",
       "    (positional_embedding): Embedding(128, 1)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (blocks): ModuleList(\n",
       "      (0): FNSDecoderBlock(\n",
       "        (self_attention): FasterFNSMultiHeadAttention(\n",
       "          (qkv_projection): Linear(in_features=1, out_features=3, bias=True)\n",
       "          (attn_dropout): Dropout(p=0, inplace=False)\n",
       "          (output_projection): Linear(in_features=1, out_features=1, bias=True)\n",
       "          (output_dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (cross_attention): FasterFNSMultiHeadAttention(\n",
       "          (kv_projection): Linear(in_features=1, out_features=2, bias=True)\n",
       "          (q_projection): Linear(in_features=1, out_features=1, bias=True)\n",
       "          (attn_dropout): Dropout(p=0, inplace=False)\n",
       "          (output_projection): Linear(in_features=1, out_features=1, bias=True)\n",
       "          (output_dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (layernorm_1): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "        (layernorm_2): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (dense_1): Linear(in_features=1, out_features=4, bias=True)\n",
       "          (activation): NewGELUActivation()\n",
       "          (dense_2): Linear(in_features=4, out_features=1, bias=True)\n",
       "          (dropout): Dropout(p=0, inplace=False)\n",
       "        )\n",
       "        (layernorm_3): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=1, out_features=58101, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, source, tokenizer_trg, max_len, device):\n",
    "    bos_idx = tokenizer_trg.bos_token_id\n",
    "    eos_idx = tokenizer_trg.eos_token_id\n",
    "\n",
    "    # Precompute the encoder output and reuse it for every step\n",
    "    encoder_output = model.encode(source)\n",
    "    # Initialize the decoder input with the sos token\n",
    "    decoder_input = torch.empty(1, 1).fill_(bos_idx).type_as(source).to(device)\n",
    "    while True:\n",
    "        if decoder_input.size(1) == max_len:\n",
    "            break\n",
    "\n",
    "        # build causal mask for target \n",
    "        decoder_mask = torch.triu(torch.ones((1, decoder_input.size(1), decoder_input.size(1))), diagonal=1).type(torch.int)\n",
    "        decoder_mask = (decoder_mask == 0).type_as(source_mask).to(device)\n",
    "\n",
    "        # calculate output\n",
    "        out = model.decode(encoder_output, source_mask, decoder_input, decoder_mask)\n",
    "\n",
    "        # get next token\n",
    "        prob = model.project(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        decoder_input = torch.cat(\n",
    "            [decoder_input, torch.empty(1, 1).type_as(source).fill_(next_word.item()).to(device)], dim=1\n",
    "        )\n",
    "\n",
    "        if next_word == eos_idx:\n",
    "            break\n",
    "\n",
    "    return decoder_input.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

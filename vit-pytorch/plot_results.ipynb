{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8bc0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcl\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from ast import literal_eval\n",
    "from itertools import product\n",
    "from matplotlib.transforms import ScaledTranslation\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from os import makedirs\n",
    "from os.path import isdir, isfile\n",
    "from pathlib import Path\n",
    "from string import ascii_lowercase\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from constants import *\n",
    "from UTILS.mutils import njoin, str2bool, str2ls, create_model_dir, convert_train_history\n",
    "from UTILS.mutils import collect_model_dirs, find_subdirs, load_model_files\n",
    "from UTILS.figure_utils import matrixify_axs, label_axs\n",
    "from plot_results import get_metric_curves, load_seed_runs, final_epoch_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fc061e",
   "metadata": {},
   "source": [
    "# Phase ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8affa317",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'njoin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m models_root \u001b[38;5;241m=\u001b[39m \u001b[43mnjoin\u001b[49m(DROOT, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4L-ps=2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# collect subdirs containing the model directories\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_root_dirs \u001b[38;5;241m=\u001b[39m models_roots \u001b[38;5;241m=\u001b[39m find_subdirs(models_root, MODEL_SUFFIX)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'njoin' is not defined"
     ]
    }
   ],
   "source": [
    "models_root = njoin(DROOT, '4L-ps=2')\n",
    "\n",
    "# collect subdirs containing the model directories\n",
    "model_root_dirs = models_roots = find_subdirs(models_root, MODEL_SUFFIX)\n",
    "print(model_root_dirs)                  \n",
    "\n",
    "# all trained model types\n",
    "model_types = []   \n",
    "DCT_ALL = {} \n",
    "for model_root_dir in model_root_dirs:\n",
    "    DCT_cur = collect_model_dirs(model_root_dir, suffix=MODEL_SUFFIX)\n",
    "    for model_type, df_model_cur in DCT_cur.items():\n",
    "        df_clean = df_model_cur.dropna(subset='alpha') if 'alpha' in df_model_cur.columns else df_model_cur\n",
    "        if model_type not in DCT_ALL:\n",
    "            model_types.append(model_type)\n",
    "            DCT_ALL[model_type] = df_clean\n",
    "        else:\n",
    "            DCT_ALL[model_type] = pd.concat([DCT_ALL[model_type], df_clean], ignore_index=True)   \n",
    "\n",
    "# isolate partiulcar setting for qk_share\n",
    "df_model = DCT_ALL[[model_type for model_type in list(DCT_ALL.keys()) if fns_manifold in model_type][0]]\n",
    "df_model.reset_index(drop=True, inplace=True)\n",
    "qk_shares = list(df_model.loc[:,'qk_share'].unique())            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55d823b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['rdfnsvit', 'opdpvit', 'oprdfnsvit', 'dpvit'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCT_ALL.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349589a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cifar10'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DCT_ALL[list(DCT_ALL.keys())[0]].loc[:,'dataset_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812ce0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('Q://scratch//uu69//cq5024//projects//fractional-attn//vit-pytorch//.droot//4L-ps=2//config_qkv//cifar10//layers=4-heads=6-hidden=48-qkv//dpvit-cifar10-qkv//model=0//run_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ab4511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>iter</th>\n",
       "      <th>lr</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>secs_per_eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>782</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.064233</td>\n",
       "      <td>1.933128</td>\n",
       "      <td>0.212935</td>\n",
       "      <td>0.258161</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1564</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.887160</td>\n",
       "      <td>1.817175</td>\n",
       "      <td>0.280291</td>\n",
       "      <td>0.317576</td>\n",
       "      <td>25.863362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2346</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.765761</td>\n",
       "      <td>1.675470</td>\n",
       "      <td>0.318994</td>\n",
       "      <td>0.359773</td>\n",
       "      <td>23.614602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3128</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.695333</td>\n",
       "      <td>1.664246</td>\n",
       "      <td>0.345408</td>\n",
       "      <td>0.366441</td>\n",
       "      <td>23.750036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3910</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>1.638615</td>\n",
       "      <td>1.583613</td>\n",
       "      <td>0.364850</td>\n",
       "      <td>0.398388</td>\n",
       "      <td>23.821391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>245</td>\n",
       "      <td>192372</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.544838</td>\n",
       "      <td>0.774390</td>\n",
       "      <td>0.806025</td>\n",
       "      <td>0.733977</td>\n",
       "      <td>24.138856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>246</td>\n",
       "      <td>193154</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.544255</td>\n",
       "      <td>0.777900</td>\n",
       "      <td>0.807505</td>\n",
       "      <td>0.732982</td>\n",
       "      <td>24.300847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>247</td>\n",
       "      <td>193936</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.547899</td>\n",
       "      <td>0.779497</td>\n",
       "      <td>0.804807</td>\n",
       "      <td>0.733380</td>\n",
       "      <td>24.111060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>248</td>\n",
       "      <td>194718</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.541615</td>\n",
       "      <td>0.774529</td>\n",
       "      <td>0.806965</td>\n",
       "      <td>0.736167</td>\n",
       "      <td>24.493165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>249</td>\n",
       "      <td>195500</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.544952</td>\n",
       "      <td>0.781436</td>\n",
       "      <td>0.805866</td>\n",
       "      <td>0.733281</td>\n",
       "      <td>24.232768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    iter       lr  train_loss  val_loss  train_acc   val_acc  \\\n",
       "0             0     782  0.00010    2.064233  1.933128   0.212935  0.258161   \n",
       "1             1    1564  0.00010    1.887160  1.817175   0.280291  0.317576   \n",
       "2             2    2346  0.00010    1.765761  1.675470   0.318994  0.359773   \n",
       "3             3    3128  0.00010    1.695333  1.664246   0.345408  0.366441   \n",
       "4             4    3910  0.00010    1.638615  1.583613   0.364850  0.398388   \n",
       "..          ...     ...      ...         ...       ...        ...       ...   \n",
       "245         245  192372  0.00001    0.544838  0.774390   0.806025  0.733977   \n",
       "246         246  193154  0.00001    0.544255  0.777900   0.807505  0.732982   \n",
       "247         247  193936  0.00001    0.547899  0.779497   0.804807  0.733380   \n",
       "248         248  194718  0.00001    0.541615  0.774529   0.806965  0.736167   \n",
       "249         249  195500  0.00001    0.544952  0.781436   0.805866  0.733281   \n",
       "\n",
       "     secs_per_eval  \n",
       "0              NaN  \n",
       "1        25.863362  \n",
       "2        23.614602  \n",
       "3        23.750036  \n",
       "4        23.821391  \n",
       "..             ...  \n",
       "245      24.138856  \n",
       "246      24.300847  \n",
       "247      24.111060  \n",
       "248      24.493165  \n",
       "249      24.232768  \n",
       "\n",
       "[250 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7622b9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_ensembles(models_root, selected_dataset='cifar10',\n",
    "                    fns_manifold='rd', qk_share=True, selected_alphas='1,2',\n",
    "                    metrics='val_acc,val_loss',\n",
    "                    is_ops = [True],  # [False,True]\n",
    "                    cbar_separate=False, display=False):\n",
    "\n",
    "    global qk_shares\n",
    "\n",
    "    assert fns_manifold in ['sp', 'rd', 'v2_rd'], f'{fns_manifold} does not exist!'\n",
    "    qk_share, cbar_separate, display = map(str2bool, (qk_share, cbar_separate, display))\n",
    "    metrics, is_ops = str2ls(metrics), str2ls(is_ops)\n",
    "\n",
    "    # collect subdirs containing the model directories\n",
    "    model_root_dirs = models_roots = find_subdirs(njoin(models_root), MODEL_SUFFIX)\n",
    "    print(model_root_dirs)                  \n",
    "\n",
    "    # all trained model types\n",
    "    model_types = []   \n",
    "    DCT_ALL = {} \n",
    "    for model_root_dir in model_root_dirs:\n",
    "        DCT_cur = collect_model_dirs(model_root_dir, suffix=MODEL_SUFFIX)\n",
    "        for model_type, df_model_cur in DCT_cur.items():\n",
    "            df_clean = df_model_cur.dropna(subset='alpha') if 'alpha' in df_model_cur.columns else df_model_cur\n",
    "            if model_type not in DCT_ALL:\n",
    "                model_types.append(model_type)\n",
    "                DCT_ALL[model_type] = df_clean\n",
    "            else:\n",
    "                DCT_ALL[model_type] = pd.concat([DCT_ALL[model_type], df_clean], ignore_index=True)                    \n",
    "\n",
    "    # isolate partiulcar setting for qk_share\n",
    "    df_model = DCT_ALL[[model_type for model_type in list(DCT_ALL.keys()) if fns_manifold in model_type][0]]\n",
    "    df_model.reset_index(drop=True, inplace=True)\n",
    "    qk_shares = list(df_model.loc[:,'qk_share'].unique())\n",
    "    print(qk_shares)\n",
    "    assert qk_share in qk_shares, f'qk_share = {qk_share} setting does not exist!'\n",
    "    \n",
    "    # print('df_model')\n",
    "    # print(df_model)\n",
    "\n",
    "    # ---- col names ----\n",
    "    stats_colnames = ['min', 'max', 'mid', 'median', 'mean', 'std', 'counter']   \n",
    "\n",
    "    # ----- general settings -----\n",
    "    num_attention_heads, num_hidden_layers, hidden_size =\\\n",
    "         DCT_ALL[list(DCT_ALL.keys())[0]].loc[0,['num_attention_heads', 'num_hidden_layers', 'hidden_size']]\n",
    "    #dataset = DCT_ALL[list(DCT_ALL.keys())[0]].loc[0,'dataset_name']\n",
    "    assert selected_dataset in DCT_ALL[list(DCT_ALL.keys())[0]].loc[:,'dataset_name'].unique(), 'selected_dataset does not exist'\n",
    "\n",
    "    # ----- fns setting -----\n",
    "    alphas = sorted(df_model.loc[:,'alpha'].unique())[::-1]  # large to small\n",
    "    epss = sorted(df_model.loc[:,'bandwidth'].unique())    \n",
    "    if selected_alphas.lower() == 'none':\n",
    "        selected_alphas = alphas\n",
    "    else:\n",
    "        selected_alphas = [float(selected_alpha) for selected_alpha in str2ls(selected_alphas)]\n",
    "    #eps = epss[0]\n",
    "    eps = 1  # hard coded\n",
    "\n",
    "    # ----- models to plot -----\n",
    "    fns_model_type = fns_manifold + 'fns' + MODEL_SUFFIX    \n",
    "    other_model_types = ['dp' + MODEL_SUFFIX]  # 'sink' + MODEL_SUFFIX\n",
    "    model_types_to_plot = [fns_model_type] + other_model_types\n",
    "            \n",
    "    print(f'model_types_to_plot: {model_types_to_plot}')\n",
    "\n",
    "    nrows, ncols = len(metrics), len(is_ops)     \n",
    "    # figsize = (3*ncols,3.5*nrows)\n",
    "    fig, axs = plt.subplots(nrows,ncols,figsize=(5,4))\n",
    "    # axs = matrixify_axs(axs, nrows, ncols)  # convert axs to 2D array\n",
    "    # label_axs(fig, axs)  # alphabetically label subfigures             \n",
    "\n",
    "    model_types_plotted = []\n",
    "    model_types_seeds = {}     \n",
    "    for (row_idx, metric), (col_idx, is_op) in product(enumerate(metrics), enumerate(is_ops)):\n",
    "        ax = axs[row_idx, col_idx] \n",
    "        # summary statistics\n",
    "        row_stats = []\n",
    "\n",
    "        print(f'model_type = {model_type}')        \n",
    "        for model_type in model_types_to_plot:\n",
    "            if is_op:\n",
    "                model_type = 'op' + model_type\n",
    "            if model_type in DCT_ALL.keys():\n",
    "                df_model = DCT_ALL[model_type]\n",
    "            else:\n",
    "                continue\n",
    "            # matching conditions for model setup\n",
    "            condition0 = (df_model['ensembles']>0)&(df_model['qk_share']==qk_share)&(df_model['is_op']==is_op)&\\\n",
    "                         (df_model['model_dir'].str.contains(selected_dataset))&\\\n",
    "                         (df_model['model_dir'].str.contains(f'/{model_type}-'))\n",
    "            matching_df = df_model[condition0]\n",
    "\n",
    "            if model_type not in model_types_plotted:\n",
    "                model_types_plotted.append(model_type)\n",
    "\n",
    "            lstyle_model = LINESTYLE_DICT[model_type]\n",
    "            for alpha in selected_alphas:\n",
    "                is_fns = 'fns' in model_type\n",
    "                alpha = alpha if is_fns else None\n",
    "                matching_df.reset_index(drop=True, inplace=True)                \n",
    "\n",
    "                print('matching_df')\n",
    "                print(matching_df)                      \n",
    "\n",
    "                # color\n",
    "                if is_fns:\n",
    "                    color = '#2E63A6' if alpha == 1.2 else '#A4292F'\n",
    "                else:\n",
    "                    # color = 'k'\n",
    "                    color = '#636363'\n",
    "                # color = HYP_CMAP(HYP_CNORM(alpha)) if is_fns else OTHER_COLORS_DICT[model_type]  \n",
    "                # -------------------- SINK, DP -------------------- \n",
    "                model_info = matching_df \n",
    "                # -------------------- FNS --------------------\n",
    "                if is_fns:\n",
    "                    # matching conditions for FNS setup\n",
    "                    condition = (matching_df['alpha']==alpha) & (matching_df['bandwidth']==eps)\n",
    "                    model_info = model_info[condition]\n",
    "                # get aggregated training curves\n",
    "                if model_info.shape[0] > 0:\n",
    "                    seeds, qk_share = (model_info[k].item() for k in ('seeds', 'qk_share'))                \n",
    "                    epochs, run_perf_all = load_seed_runs(model_info['model_dir'].item(), seeds, metric)   \n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                if run_perf_all is not None:\n",
    "                    counter = run_perf_all.shape[1]\n",
    "                    metric_curves = get_metric_curves(run_perf_all)      \n",
    "                    exe_plot = ax.plot(epochs, metric_curves[1], linestyle='-', c=color, alpha=1, clip_on=False, label='DP' if not is_fns else rf'$\\alpha = {alpha}$')\n",
    "                    if (row_idx,col_idx) == (0,0):\n",
    "                        im = exe_plot                      \n",
    "                    # Calculate std                       \n",
    "                    metric_std = np.nanstd(run_perf_all.to_numpy(), axis=1)\n",
    "                    ax.fill_between(epochs, metric_curves[1]-metric_std, metric_curves[1]+metric_std, color=color, alpha=0.3, clip_on=False, edgecolor='none') \n",
    "\n",
    "                    # results of the final epoch\n",
    "                    row_stats.append([model_type, alpha] +\\\n",
    "                                     final_epoch_stats(run_perf_all,metric) + [counter])    \n",
    "                    ax.spines['top'].set_visible(False)\n",
    "                    ax.spines['right'].set_visible(False)\n",
    "                    ax.set_xlim([0,20])\n",
    "                    ax.set_xticks([0, 5, 10, 15, 20])\n",
    "                    if row_idx == 0:\n",
    "                        ax.set_ylim(bottom=72,top=85)\n",
    "                        ax.set_yticks([75,80,85])\n",
    "                    elif row_idx == 1:\n",
    "                        # ax.set_ylim([0.45, 0.6])\n",
    "                        ax.set_yticks([0.45, 0.5, 0.55])\n",
    "                if not is_fns:\n",
    "                    break  # only do once if model is not FNS type\n",
    "\n",
    "        summary_stats = pd.DataFrame(data=row_stats, columns=['model_type','alpha']+stats_colnames)\n",
    "\n",
    "        # print message\n",
    "        # print(metric)\n",
    "        # print(f'is_op = {is_op}, qk_share = {qk_share}')\n",
    "        # print(summary_stats)\n",
    "        # print('\\n')                    \n",
    "\n",
    "    # # labels\n",
    "    # model_labels = []\n",
    "    # for model_type in model_types_plotted:  \n",
    "    #     if model_type[:2] != 'op': \n",
    "    #         color = 'k' if 'fns' in model_type else OTHER_COLORS_DICT[model_type]            \n",
    "    #         model_label = NAMES_DICT[model_type]\n",
    "    #         if model_label not in model_labels:            \n",
    "    #             axs[0,0].plot([], [], c=color, linestyle=LINESTYLE_DICT[model_type], label=model_label)\n",
    "    #             model_labels.append(model_label)\n",
    "\n",
    "    # # legend\n",
    "    axs[0,0].legend(loc='best', frameon=False)                     \n",
    "    # for alpha in selected_alphas[::-1]:\n",
    "    #     axs[0,0].plot([], [], c=HYP_CMAP(HYP_CNORM(alpha)), linestyle='solid', \n",
    "    #                   label=rf'$\\alpha$ = {alpha}')         \n",
    "    # ncol_legend = 2  #if len(model_types_plotted) == 3 else 1\n",
    "    # if len(model_types_plotted) >= 2:\n",
    "    #     #axs[0,0].legend(loc='best', ncol=ncol_legend, frameon=False)           \n",
    "    #     axs[0,0].legend(loc='best', ncol=ncol_legend, frameon=False)                     \n",
    "\n",
    "    # Add shared x and y labels     \n",
    "    #fig.supxlabel('Epochs', fontsize='medium'); fig.supylabel(NAMES_DICT[metrics[0]], fontsize='medium')\n",
    "\n",
    "    for row_idx in range(len(qk_shares)):        \n",
    "        for col_idx, is_op in enumerate(is_ops):  \n",
    "            ax = axs[row_idx, col_idx]\n",
    "            #ax.set_ylabel(NAMES_DICT[metric])\n",
    "            if row_idx == 0:\n",
    "                #ax.set_title(NAMES_DICT[metric])\n",
    "                ax_title = r'$W \\in O(d)$' if is_ops[col_idx] else r'$W \\notin O(d)$'\n",
    "                ax.set_title(ax_title)\n",
    "            \n",
    "            axs[row_idx,col_idx].sharey(axs[row_idx, 0])\n",
    "            axs[-1,col_idx].set_xlabel('Epochs')\n",
    "        # axs[row_idx,0].set_ylabel(NAMES_DICT[metrics[row_idx]])\n",
    "    axs[0,0].set_ylabel('Testing accuracy (%)')\n",
    "    axs[1,0].set_ylabel('Testing loss')\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.3)\n",
    "    # plt.tight_layout()  # Leave space for the right label                 \n",
    "\n",
    "    dataset_name_short = ''\n",
    "    if isinstance(selected_dataset,str):\n",
    "        if '_' in selected_dataset:\n",
    "            for s in selected_dataset.split('_'):\n",
    "                dataset_name_short += s[0]\n",
    "        else:\n",
    "            dataset_name_short += selected_dataset\n",
    "\n",
    "    model_types_short = [model_type.replace(MODEL_SUFFIX,'') for model_type in model_types_plotted]\n",
    "    \n",
    "    return fig, axs\n",
    "\n",
    "    # from constants import FIGS_DIR\n",
    "    # SAVE_DIR = njoin(FIGS_DIR, 'nlp-task')\n",
    "    # if display:\n",
    "    #     plt.show()\n",
    "    # else:\n",
    "    #     if not isdir(SAVE_DIR): makedirs(SAVE_DIR)\n",
    "    #     fig_file = models_root.split('/')[1] + '-'\n",
    "    #     #fig_file += f'layers={num_hidden_layers}-heads={num_attention_heads}-hidden={hidden_size}-'            \n",
    "    #     fig_file += f'l={num_hidden_layers}-d={hidden_size}-'\n",
    "    #     fig_file += 'qqv-' if qk_share else 'qkv-'\n",
    "    #     fig_file += '_'.join(model_types_short)+ '-' + metrics[0] + '-' + f'ds={dataset_name_short}'\n",
    "    #     fig_file += '.pdf'\n",
    "    #     plt.savefig(njoin(SAVE_DIR, fig_file))            \n",
    "    #     print(f'Figure saved in {njoin(SAVE_DIR, fig_file)}')\n",
    "\n",
    "    # # separate colorbar\n",
    "    # if cbar_separate:    \n",
    "    #     \"\"\"\n",
    "    #     #fig.subplots_adjust(right=0.8)\n",
    "    #     fig = plt.figure()\n",
    "    #     cbar_ax = fig.add_axes([0.85, 0.20, 0.03, 0.75])\n",
    "    #     cbar_ticks = list(np.arange(1,2.01,0.2))\n",
    "    #     cbar = fig.colorbar(im, cax=cbar_ax, ticks=cbar_ticks)\n",
    "    #     cbar.ax.set_yticklabels(cbar_ticks)\n",
    "    #     cbar.ax.tick_params(axis='y', labelsize=tick_size)\n",
    "    #     \"\"\"\n",
    "        \n",
    "    #     fig = plt.figure()\n",
    "    #     cbar_ax = fig.add_axes([0.85, 0.20, 0.03, 0.75])\n",
    "    #     cbar_ticks = list(np.linspace(1,2,6))\n",
    "        \n",
    "    #     cbar = mpl.colorbar.ColorbarBase(cbar_ax, norm=HYP_CNORM, cmap=HYP_CM)\n",
    "    #     cbar.ax.set_yticklabels(cbar_ticks)\n",
    "    #     cbar.ax.tick_params(axis='y', labelsize=16.5)\n",
    "\n",
    "    #     plt.savefig(njoin(SAVE_DIR,\"alpha_colorbar.pdf\"), bbox_inches='tight')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe757739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q:\\\\scratch\\\\uu69\\\\cq5024\\\\projects\\\\fractional-attn\\\\vit-pytorch\\\\.droot\\\\4L-ps=2\\\\config_qkv\\\\cifar10\\\\layers=4-heads=6-hidden=48-qkv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "q:\\scratch\\uu69\\cq5024\\projects\\fractional-attn\\vit-pytorch\\UTILS\\mutils.py:216: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = df._append(model_dir_dct, ignore_index=True)\n",
      "q:\\scratch\\uu69\\cq5024\\projects\\fractional-attn\\vit-pytorch\\UTILS\\mutils.py:216: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = df._append(model_dir_dct, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n",
      "df_model\n",
      "   alpha  bandwidth    a qk_share qkv_bias dataset_name  \\\n",
      "0    1.2        1.0  0.0    False    False      cifar10   \n",
      "1    2.0        1.0  0.0    False    False      cifar10   \n",
      "2    1.2        1.0  0.0    False    False      cifar10   \n",
      "3    2.0        1.0  0.0    False    False      cifar10   \n",
      "\n",
      "                                          train_loss  \\\n",
      "0  [0.6191950440406799, 0.5639753937721252, 0.646...   \n",
      "1  [0.6191950440406799, 0.5639753937721252, 0.646...   \n",
      "2  [0.6191950440406799, 0.5639753937721252, 0.646...   \n",
      "3  [0.6191950440406799, 0.5639753937721252, 0.646...   \n",
      "\n",
      "                                            val_loss  \\\n",
      "0  [0.8076232075691223, 0.7732414603233337, 0.788...   \n",
      "1  [0.8076232075691223, 0.7732414603233337, 0.788...   \n",
      "2  [0.8076232075691223, 0.7732414603233337, 0.788...   \n",
      "3  [0.8076232075691223, 0.7732414603233337, 0.788...   \n",
      "\n",
      "                                           train_acc  \\\n",
      "0  [0.780610203742981, 0.8005113005638123, 0.7708...   \n",
      "1  [0.780610203742981, 0.8005113005638123, 0.7708...   \n",
      "2  [0.780610203742981, 0.8005113005638123, 0.7708...   \n",
      "3  [0.780610203742981, 0.8005113005638123, 0.7708...   \n",
      "\n",
      "                                             val_acc num_attention_heads  \\\n",
      "0  [0.7238255739212036, 0.7340766191482544, 0.729...                   6   \n",
      "1  [0.7238255739212036, 0.7340766191482544, 0.729...                   6   \n",
      "2  [0.7238255739212036, 0.7340766191482544, 0.729...                   6   \n",
      "3  [0.7238255739212036, 0.7340766191482544, 0.729...                   6   \n",
      "\n",
      "  num_hidden_layers patch_size hidden_size  is_op  \\\n",
      "0                 4          2          48   True   \n",
      "1                 4          2          48   True   \n",
      "2                 4          2          48  False   \n",
      "3                 4          2          48  False   \n",
      "\n",
      "                                steps_per_epoch ensembles seeds  \\\n",
      "0  0    782\n",
      "Name: steps_per_epoch, dtype: int64         1   [0]   \n",
      "1  0    782\n",
      "Name: steps_per_epoch, dtype: int64         1   [0]   \n",
      "2  0    782\n",
      "Name: steps_per_epoch, dtype: int64         1   [0]   \n",
      "3  0    782\n",
      "Name: steps_per_epoch, dtype: int64         1   [0]   \n",
      "\n",
      "                                           model_dir  \n",
      "0  q:\\scratch\\uu69\\cq5024\\projects\\fractional-att...  \n",
      "1  q:\\scratch\\uu69\\cq5024\\projects\\fractional-att...  \n",
      "2  q:\\scratch\\uu69\\cq5024\\projects\\fractional-att...  \n",
      "3  q:\\scratch\\uu69\\cq5024\\projects\\fractional-att...  \n",
      "model_types_to_plot: ['rdfnsvit', 'dpvit']\n",
      "model_type = dpvit\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [alpha, bandwidth, a, qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [alpha, bandwidth, a, qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "model_type = dpvit\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [alpha, bandwidth, a, qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [alpha, bandwidth, a, qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "model_type = opdpvit\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [alpha, bandwidth, a, qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [alpha, bandwidth, a, qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "model_type = dpvit\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [alpha, bandwidth, a, qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [alpha, bandwidth, a, qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n",
      "matching_df\n",
      "Empty DataFrame\n",
      "Columns: [qk_share, qkv_bias, dataset_name, train_loss, val_loss, train_acc, val_acc, num_attention_heads, num_hidden_layers, patch_size, hidden_size, is_op, steps_per_epoch, ensembles, seeds, model_dir]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin Qu\\AppData\\Local\\Temp\\ipykernel_13252\\4204891574.py:172: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  axs[0,0].legend(loc='best', frameon=False)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from constants import FIGS_DIR\n",
    "fig, axs = phase_ensembles(njoin(DROOT, '4L-ps=2'), is_ops=[False,True], selected_alphas='1.2,2', qk_share=False)\n",
    "# plt.tight_layout()\n",
    "# SAVE_DIR = njoin(FIGS_DIR, 'vit-task')    \n",
    "# fig_file = 'phase_ensembles'\n",
    "# fig_file += '.pdf'\n",
    "# #plt.savefig(njoin(SAVE_DIR, fig_file), bbox_inches='tight')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.11 ('fracformer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "02ebf463265a38044231b94d9d261397dd6120542826c5cf420973e066642d92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
